# Emmotion-and-Hand-Gesture-Based-Music-Recommendation-System
This hybrid music recommendation system combines hand gestures and facial emotion detection for user interaction. It uses MediaPipe with TensorFlow for gesture recognition and a FER algorithm for facial analysis. The system prioritizes gestures, followed by emotions, for selecting music. It identifies Navarasa (nine emotions) using computer vision techniques and maps them to Melakarta ragas for personalized recommendations. Tools used include Python, scikit-learn, and OpenCV.


 This project proposes an AI-based music recommendation system that uses real-time hand gestures and facial emotion recognition via webcam to suggest personalized songs. By combining gesture and emotion detection with machine learning, the system maps emotional states to suitable music (e.g., ragas) to enhance the user's mood and listening experience. Deliverables include a working system and detailed documentation.

<img src="https://github.com/user-attachments/assets/eb85b12f-11b8-4a60-9812-d10cb3b8ef78" alt="flowchart" width="300"/>



